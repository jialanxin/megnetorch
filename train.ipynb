{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch:0\n",
      "Time:125944.3828125\n",
      "Loss:0.17136768996715546\n",
      "epoch:1\n",
      "Time:253809.9375\n",
      "Loss:0.15539903938770294\n"
     ]
    }
   ],
   "source": [
    "from dataset import StructureRamanDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "import json\n",
    "from model import MegNet\n",
    "import torch\n",
    "import time\n",
    "\n",
    "with open(\"Structures.pkl\",\"rb\") as f:\n",
    "    structures = pickle.load(f)\n",
    "\n",
    "with open(\"Raman_encoded_JVASP_90000.json\",\"r\") as f:\n",
    "    ramans = json.loads(f.read())\n",
    "\n",
    "def collate_fn(structure_list):\n",
    "    num_of_structures = len(structure_list)\n",
    "    atoms_of_all = []\n",
    "    state_of_all = []\n",
    "    bonds_of_all = []\n",
    "    bond_atom_1_of_all = []\n",
    "    bond_atom_2_of_all = []\n",
    "    ramans_of_all = []\n",
    "    for i in range(num_of_structures):\n",
    "        inputs,ramans = structure_list[i]\n",
    "        atoms, state, bonds,bond_atom_1,bond_atom_2 = inputs[\"atoms\"],inputs[\"state\"],inputs[\"bond_length\"],inputs[\"bond_atom_1\"],inputs[\"bond_atom_2\"]\n",
    "        atoms_of_all.append(atoms)\n",
    "        state_of_all.append(state)\n",
    "        bonds_of_all.append(bonds)\n",
    "        bond_atom_1_of_all.append(bond_atom_1)\n",
    "        bond_atom_2_of_all.append(bond_atom_2)\n",
    "        ramans_of_all.append(ramans)\n",
    "    return (torch.LongTensor(atoms_of_all),torch.Tensor(state_of_all),torch.Tensor(bonds_of_all),torch.LongTensor(bond_atom_1_of_all),torch.LongTensor(bond_atom_2_of_all),torch.Tensor(ramans_of_all))\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "dataset = StructureRamanDataset(structures,ramans)\n",
    "data_loader = DataLoader(dataset=dataset,batch_size=None,collate_fn=collate_fn,sampler=dataset.data_info.keys())\n",
    "net = MegNet().to(device)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end   = torch.cuda.Event(enable_timing=True)\n",
    "start.record()\n",
    "for epoch in range(2):\n",
    "    accumulate_loss = torch.Tensor([[0.0]]).to(device)\n",
    "    for i ,data in enumerate(data_loader):\n",
    "        atoms, state, bonds,bond_atom_1,bond_atom_2,ramans = data\n",
    "        predicted_spectrum = net(atoms.to(device),state.to(device),bonds.to(device),bond_atom_1.to(device),bond_atom_2.to(device))\n",
    "        loss = loss_func(predicted_spectrum,ramans.to(device))\n",
    "        loss.backward()\n",
    "        accumulate_loss += loss\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    accumulate_loss = accumulate_loss/(i+1)\n",
    "    end.record()\n",
    "    torch.cuda.synchronize() \n",
    "    print(f\"epoch:{epoch}\")\n",
    "    print(f\"Time:{start.elapsed_time(end)}\")\n",
    "    print(f\"Loss:{accumulate_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end   = torch.cuda.Event(enable_timing=True)\n",
    "start.record()\n",
    "for epoch in range(2,102):\n",
    "    accumulate_loss = torch.Tensor([[0.0]]).to(device)\n",
    "    for i ,data in enumerate(data_loader):\n",
    "        atoms, state, bonds,bond_atom_1,bond_atom_2,ramans = data\n",
    "        predicted_spectrum = net(atoms.to(device),state.to(device),bonds.to(device),bond_atom_1.to(device),bond_atom_2.to(device))\n",
    "        loss = loss_func(predicted_spectrum,ramans.to(device))\n",
    "        loss.backward()\n",
    "        accumulate_loss += loss\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    accumulate_loss = accumulate_loss/(i+1)\n",
    "    end.record()\n",
    "    torch.cuda.synchronize() \n",
    "    print(f\"epoch:{epoch}\")\n",
    "    print(f\"Time:{start.elapsed_time(end)}\")\n",
    "    print(f\"Loss:{accumulate_loss.item()}\")"
   ]
  }
 ]
}